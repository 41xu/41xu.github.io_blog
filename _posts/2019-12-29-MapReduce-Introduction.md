---
Matitleï¼š	MapReduceç®€å•ä»‹ç»+ä»£ç å®ç°
tag:	Hadoop
---

> ä¸Šä¸€ç¯‡åšå®¢å·²ç»æ˜¯ä¸€å¹´å‰äº†...ä¸Šä¸€ç¯‡åšå®¢é‡Œç®€å•ä»‹ç»äº†Hadoopå’ŒHDFS
>
> è¿™ç¯‡æˆ‘ä»¬å°±æ¥è°ˆè°ˆMapReduceåŠç›¸å…³ä»£ç å®ç°å§ï¼
>
> ç…§ä¾‹é™„ä¸Š[å®˜ç½‘é“¾æ¥](http://hadoop.apache.org/docs/r1.0.4/cn/quickstart.html)

>Hadoopç³»åˆ—æ–‡ç« 002

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

## MapReduce æ¦‚è¿°

Map/Reduceæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶ï¼Œç”¨äºå¯¹æµ·é‡æ•°æ®è¿›è¡Œå¹¶è¡Œåˆ†æå’Œå¤„ç†ã€‚

Map/Reduceåˆ†ä¸º**Map(æ˜ å°„)**å’Œ**Reduce(åŒ–ç®€)**ä¸¤ä¸ªé˜¶æ®µï¼Œæ˜¯åœ¨HDFSå­˜å‚¨æ•°æ®çš„åŸºç¡€ä¸Šï¼Œå°†ä¸€ä¸ªè¾ƒå¤§çš„è®¡ç®—ä»»åŠ¡**(job)**åˆ†è§£æˆè‹¥å¹²å°ä»»åŠ¡**(task)**ï¼Œæ¯ä¸ªå°ä»»åŠ¡éƒ½ç”±ä¸€ä¸ªMapä»»åŠ¡(task)æ¥è®¡ç®—ï¼ˆè¿™ä¸ªMapå°½é‡åœ¨æ•°æ®æ‰€åœ¨èŠ‚ç‚¹ä¸Šå®Œæˆè®¡ç®—ï¼‰ï¼Œç„¶åå†å°†æ¯ä¸ªMapçš„è®¡ç®—ç»“æœç”±ä¸€ä¸ªæˆ–å¤šä¸ªReduceä»»åŠ¡(task)åˆå¹¶ï¼Œå¾—åˆ°æœ€ç»ˆçš„ç»“æœã€‚

æ¦‚æ‹¬æ¥è¯´å°±æ˜¯æ¯”è¾ƒå¸¸è§çš„**â€œåˆ†æ²»â€**æ³•ï¼Œå’Œå¿«æ’é‡Œçš„åˆ†æ²»ï¼Œç„¶ååˆå¹¶çš„æ€æƒ³æ˜¯ä¸€æ ·çš„ï¼

ä¸¾ä¸ªğŸŒ°ï¼šå¦‚æœç°åœ¨çš„ä»»åŠ¡æ˜¯è®¡ç®—`1+5+7  +3+4+9 +3+5+6=?` é‚£ä¹ˆè¿™ä¸ªè®¡ç®—è¿‡ç¨‹åœ¨MapReduceé‡Œå°±æ˜¯è¿™æ ·çš„ï¼š

```
Map:	1+5+7			3+4+9			3+5+6

Reduce:		13+16+14 
						|
					  43
```

Map/Reduceæ¡†æ¶ç”±ä¸€ä¸ªå•ç‹¬çš„**master**`JobTracker`å’Œæ¯ä¸ªé›†ç¾¤èŠ‚ç‚¹ä¸€ä¸ª**slave**`TaskTracker`å…±åŒç»„æˆï¼Œmasterè´Ÿè´£è°ƒåº¦ä¸€ä¸ªä½œä¸šçš„æ‰€æœ‰ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡åˆ†å¸ƒåœ¨ä¸åŒçš„slaveä¸Šç”±masterç›‘æ§æ‰§è¡Œã€‚

<img src="../img/mapreduce.png" alt="mapreduceè¿‡ç¨‹" style="zoom:40%;" />

##MapReduce ç¼–ç¨‹æ€æƒ³ 

> é€šè¿‡ä¸Šé¢çš„ğŸŒ°ï¼Œæˆ‘ä»¬çŸ¥é“äº†MapReduceæœ¬è´¨ä¸Šå°±æ˜¯æ™®æ™®é€šé€šçš„åˆ†æ²»ã€‚ä½†æ˜¯...å…‰æ˜¯è¿™æ ·ç®€å•çš„äº†è§£å¥½åƒè¿˜ä¸å¤ªèƒ½å¤Ÿå†™ä»£ç å“¦..é‚£ä¹ˆæ¥ä¸‹æ¥çœ‹çœ‹ç¼–ç¨‹æ€æƒ³å§ï¼

MapReduceæ“ä½œæ•°æ®çš„æœ€å°å•ä½æ˜¯ä¸€ä¸ª**é”®å€¼å¯¹**ï¼Œå¯¹æ²¡é”™ï¼Œå°±æ˜¯ä½ æƒ³çš„é‚£ä¸ª**key-value**ï¼æˆ‘ä»¬åœ¨ä½¿ç”¨MapReduceæ¨¡å‹çš„æ—¶å€™ï¼Œç¬¬ä¸€æ­¥å°±è¦å°†æ•°æ®æŠ½è±¡ä¸ºkey-valueçš„å½¢å¼ï¼Œæ¥ä¸‹æ¥mapå‡½æ•°ä¼šä»¥key-valueä½œä¸ºè¾“å…¥ï¼Œç»è¿‡ä½ å†™çš„mapå‡½æ•°çš„å¤„ç†ï¼Œä¼šç”Ÿæˆä¸€ç³»åˆ—æ–°çš„é”®å€¼å¯¹ä½œä¸ºä¸­é—´ç»“æœè¾“å‡ºåˆ°æœ¬åœ°ã€‚ç„¶åMapReducè¿™ä¸ªæ¡†æ¶ä¼šè‡ªåŠ¨å°†ä¸­é—´ç»“æœæŒ‰ç…§keyåšèšåˆï¼Œå¹¶å°†**keyç›¸åŒçš„æ•°æ®**åˆ†å‘ç»™reduceå‡½æ•°å¤„ç†ï¼Œreduceå‡½æ•°ä»¥åŒæ ·çš„keyå’Œå¯¹åº”çš„valueä½œä¸ºè¾“å…¥å¤„ç†åäº§ç”Ÿå¦ä¸€ç³»åˆ—çš„key-valueä½œä¸ºè¾“å‡ºã€‚

æœ€ç®€å•çš„map-reduceå¯ä»¥ç†è§£æˆï¼Œå‡ ä¸ªnodeæŒ‰ç…§è‡ªå·±åˆ†åˆ°çš„æ•°æ®ï¼ŒæŒ‰ç…§ä½ å†™çš„mapçš„åŠŸèƒ½ï¼Œå°†æ•°æ®åˆ†æˆæœ‰è§„å¾‹çš„map-reduceç„¶åå‡ ä¸ªnodeæŠŠè‡ªå·±çš„è®¡ç®—ç»“æœæ€¼ç»™è´Ÿè´£reduceçš„nodeï¼Œè¿™ä¸ªreduceä¹Ÿæ˜¯æŒ‰ç…§ä½ å†™çš„reduceçš„åŠŸèƒ½å°†åŒæ ·mapçš„æ•°æ®åˆå¹¶åˆå¹¶ï¼Œä¹‹åè¾“å‡ºæ–°çš„map-reduce. å½“ç„¶ï¼Œæ•´ä¸ªè¿‡ç¨‹çš„reduceå…¶å®å¯ä»¥æ‰§è¡Œå¤šæ¬¡ã€‚

è¿™é‡Œä¸€ä¸ªæ³¨æ„çš„åœ°æ–¹æ˜¯ï¼š**reduceçš„è¾“å…¥ç±»å‹å¿…é¡»å’Œmapçš„è¾“å‡ºç±»å‹ä¸€è‡´ï¼ï¼**ï¼Œå‰©ä¸‹çš„è¾“å…¥è¾“å‡ºéšæ„ã€‚

## è¿è¡Œä¸€ä¸‹MapReduceä¾‹ç¨‹WordCountå§ï¼

WordCountå¯ä»¥ç»Ÿè®¡è¾“å…¥çš„æ–‡ä»¶å¤¹ä¸‹çš„å¤šä¸ªæ–‡æ¡£ä¸­æ¯ä¸ªå•è¯çš„å‡ºç°æ¬¡æ•°.

æµç¨‹ï¼š

1. å¯åŠ¨YARNå’Œjobhistoryï¼ˆå…³äºè¿™ä¿©çš„ä»‹ç»æˆ‘ä»¬æ”¾åœ¨ä¸‹ä¸€ç¯‡åšå®¢ æˆ–è€…æ˜¯è®©æˆ‘æ‚„æ‚„ç¼–è¾‘ä¸€ä¸‹è¿™ç¯‡åšå®¢æ·»åŠ ä¸€ä¸‹å§Orzï¼‰

   ```
   cd hadoop-x.x.x/sbin // å°±æ˜¯cd $HADOOP_HOME/sbin
   ./start-yarn.sh
   ./mr-jobhistory-daemon.sh start historyserver
   ```

2. ä¸Šä¼ æƒ³è¦ç»Ÿè®¡çš„æœ¬åœ°æ–‡æ¡£åˆ°HDFSä¸­

   ```
   hdfs dfs -mkdir -p /expr/wordcount/data
   hdfs dfs -put xxxxfilexxxx /expr/wordcount/data
   ```

3. å¯ä»¥è¿è¡Œäº†

   ```
   cd hadoop-x.x.x/share/hadoop/mapreduce
   hadoop jar hadoop-mapreduce-examples-2.8.5.jar wordcount /expr/wordcount/data /expr/wordcount/output // è§£é‡Šä¸€ä¸‹å°±æ˜¯è¿è¡Œäº†exampleé‡Œçš„wordcount wordcountçš„è¾“å…¥åœ¨HDFSçš„/expr/wordcount/dataä¸­ï¼Œè¾“å‡ºç»“æœåœ¨/expr/wordcount/outputä¸­ï¼ˆè¿™ä¸ªç›®å½•ç¨‹åºè‡ªåŠ¨åˆ›å»ºçš„
   ```

4. æŸ¥çœ‹ç»“æœ

   ```
   ç°åœ¨/expr/wordcount/é‡Œæ˜¯è¿™æ ·çš„ï¼š
   drwxr-xr-x   - xusy supergroup          0 2019-12-29 16:44 /expr/wordcount/data
   drwxr-xr-x   - xusy supergroup          0 2019-12-29 16:46 /expr/wordcount/output
   outputé‡Œå­˜çš„wordcountçš„ç»“æœ,outputé‡Œé•¿è¿™æ ·
   -rw-r--r--   1 xusy supergroup          0 2019-12-29 16:46 /expr/wordcount/output/_SUCCESS
   -rw-r--r--   1 xusy supergroup         71 2019-12-29 16:46 /expr/wordcount/output/part-r-00000
   æ‰§è¡Œè¿™ä¸ªğŸ‘‰ğŸ¿hdfs dfs -cat /expr/wordcount/output/part-r-00000å°±å¯ä»¥çœ‹ç»“æœäº†
   ```

   å¯ä»¥åœ¨/dataä¸‹é¢å¤šä¼ å‡ ä¸ªæ–‡æ¡£ï¼Œä¸€èµ·è¢«ç»Ÿè®¡wordcountï¼Œå“‡çœŸçš„å¥½æ–¹ä¾¿ï¼

å¯ä»¥çœ‹çœ‹è¿™ä¸ªæµç¨‹å›¾åŠ æ·±å°è±¡

<img src="../img/wordcount.png" alt="wordoucnt" style="zoom:40%;" />

å½“ç„¶ä½ ä¹Ÿå¯ä»¥åˆ°ä¸Šé¢å­˜æ”¾ä¾‹ç¨‹çš„ä½ç½®æ‰“å¼€.jar-> WordCount.javaçœ‹çœ‹æºç ï¼Œæ–‡ç« å¼€å¤´çš„å®˜ç½‘é“¾æ¥ä¸­ä¹Ÿæœ‰ç›¸å…³æºç ä»‹ç»ã€‚

MapperğŸ‘‡ğŸ¼

```java
	public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable> {		
			private final static IntWritable one = new IntWritable(1);
			private Text word = new Text();

			public void map(Object key, Text value, Context context ) throws IOException, InterruptedException {
	    		StringTokenizer itr = new StringTokenizer(value.toString());
	    		while (itr.hasMoreTokens()) {
	    			word.set(itr.nextToken());
	    			context.write(word, one);
	    		}
	   	 }
	}
```

ReducerğŸ‘‡ğŸ¼

```java
	public static class IntSumReducer extends Reducer<Text,IntWritable,Text,IntWritable> {
			private IntWritable result = new IntWritable();
		
			public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
				int sum = 0;
				for (IntWritable val : values) {
					sum += val.get();
				}
				result.set(sum);
				context.write(key, result);
	    	}
	}
```

## è‡ªå·±å†™mapperå’Œreducerç±»ï¼

å¦‚æœä½ æ‰“å¼€çœ‹äº†wordcountçœ‹äº†æºç çš„è¯..è¿™é‡Œä¼šæ›´åŠ æ¸…æ¥šmapperå’Œreducer classåˆ°åº•æ˜¯æŒ‰ç…§å•¥æµç¨‹å†™çš„ï¼Œå½“ç„¶æ²¡çœ‹ä¹Ÿæ²¡å…³ç³»ï¼Œæˆ‘ä»¬ä¸€èµ·æ€»ç»“ä¸€ä¸‹è¿™ç©æ„åˆ°åº•å’‹å†™ï¼

1. é¦–å…ˆï¼Œæƒ³ç”¨Map/Reduceæ¡†æ¶ï¼Œæˆ‘ä»¬è¦å…ˆè®¾ç½®å¥½è¿™æ¬¡ä½œä¸šJobçš„ä¸€äº›ä¿¡æ¯ï¼š

   ```java
   public static void main(String[] args)throws Exception{
     	//1.è®¾ç½®å¥½HDFSçš„é…ç½®ä¿¡æ¯
     	Configuration conf = new Configuration();
     	String hdfs = "hdfs://xusy:9000"; //å› ä¸ºæˆ‘ç”¨çš„æœ¬æœºæçš„ä¼ªåˆ†å¸ƒï¼Œæˆ‘çš„masteråå­—å°±æ˜¯xusy,å¯¹åº”HDFSç«¯å£9000
     	conf.set("fs.default.name",hdfs);
       //2.è®¾ç½®å¥½MapReduceçš„ä½œä¸šé…ç½®ä¿¡æ¯
     	String jobName = "xxxx";
     	Job job = Job.getInstance(conf, jobName);
     	job.setJarByClass(xxxx.class);
     	job.setMapperClass(yourMapper.class);
   		job.setCombinerClass(yourReducer.class);		
   		job.setReducerClass(yourReducer.class);
   		job.setOutputKeyClass(Text.class); //output
   		job.setOutputValueClass(IntWritable.class); 
     	//3.è®¾ç½®ä½œä¸šçš„è¾“å…¥è¾“å‡ºè·¯å¾„
     	String dataDir = "xxxx"; //è¾“å…¥è·¯å¾„ å¯ä»¥æ˜¯/xxxx/data
     	String outputDir = "xxxx"; //è¾“å‡ºè·¯å¾„ /xxxx/output
     	Path inPath = new Path(hdfs + dataDir);
     	Path outPath = new Path(hdfs + outputDir);
     	FileInputFormat.addInputPath(job, inPath);
     	FileOutputFormat.setOutputPath(job, outPath);
     	//å¦‚æœè¾“å‡ºç›®å½•å·²å­˜åœ¨åˆ™åˆ é™¤
     	FileSystem fs = FileSystem.get(conf);
     	if(fs.exists(outPath)){
         	fs.delete(outPath, true);
      	}
     	//4.è¿è¡Œä½œä¸š
     	System.out.println("Job: " + jobName + "is running..."); //å¯é€‰çš„è¾“å‡ºå•¦~è¿™æ ·è¾“å‡ºä¼šæ›´å¥½çœ‹ä¸€äº›
     	if(job.waitForCompletion(true)){
         	System.out.println("success!");
         	System.exit(0);
       } else{
         	System.out.println("failed!");
         	System.exit(1);
       }
   }
   ```

2. ä¸Šé¢çš„jobéƒ½è®¾ç½®å¥½äº†ä¹‹åï¼Œå‰©ä½™çš„å·¥ä½œå°±æ˜¯å†™ä½ çš„Mapperå’ŒReduceräº†

   ```java
   
   ```

   

