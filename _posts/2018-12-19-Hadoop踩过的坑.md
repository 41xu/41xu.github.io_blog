---
title:	Hadoop中踩过的坑记录
tags:	Hadoop
---

> Hadoop踩坑了怎么办？Hadoop屡次踩坑怎么办？？？先记下来以后遇到了再查吧..哭泣..

## 1. 启动的时候命令都运行了但jps之后还是有节点没启动怎么办？

A：首先先到之前的安装记录中查对应的配置文件，是不是哪里写错啦你没发现...第一次遇到有节点没起来的话，那么多半是配置有问题。

## 2. 启动之后datanode起不来怎么办？（甚至可能会出现namenode起不来？）

A：网上查阅了诸多解决办法，从修改配置文件的相关log存储位置，到修改namenode, datanode相关的配置信息..都试过了然而没用...(Orz暴风哭泣我也很绝望啊)

这个时候..先把他们都关掉！stop-all.sh！！之后！！在启动之前！!
```
hadoop namenode -format
```
然后重新启动就行了..

## 3. datanode启动成功了 但是namenode又启动失败了怎么办？

A：一般都是配置文件出了问题...（那我上一个问题在回答什么呢在说屁话吗...）

仔细检查了自己的配置发现是没有问题的..（甚至模模糊糊的记得老师说过伪分布式的Hadoop在搭建的时候配置文件里如果写localhost可能会不太好会有一些迷之报错因此还跑去sudo vim /etc/hosts 把127.0.0.1解析的名字换成了xusy然而还是不太行...）

**最后对2，3两个问题的总结：** 跑到Hadoop/hadoop-2.8.5/log里面看了日志..发现datanode里有这样的log：
```
2018-12-19 21:18:18,052 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN, trace:
java.lang.Exception
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:210)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.hasBlockPoolId(BPOfferService.java:220)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdownBlockPool(DataNode.java:1491)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.shutdownActor(BPOfferService.java:465)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.cleanUp(BPServiceActor.java:527)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:787)
	at java.lang.Thread.run(Thread.java:748)
2018-12-19 21:18:20,055 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2018-12-19 21:18:20,057 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 0
2018-12-19 21:18:20,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
```
上网搜了一下解决办法是
```
mv /Users/xusy/Documents/Hadoop/dfs/data/current /Users/xusy/Documents/Hadoop/dfs/data/current.bak
```
然后重新启动就好了..因为过时的文件找不到信息，之前疯狂修改tmp文件夹和缓存的路径也是这个原因(这个在安装的那个博客里后面有更新，但这个方法好像是针对集群来讲比较有用)所以最本质还是过时的文件NN找不到信息，我们mv .bak就可以了...

*..所以..遇到问题..还是要点进log里自己看看报错信息然后解决可能会更好点呀...*







> continue..持续更新欢迎关注..